{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sid-cd/DNA-Detectives-Program/blob/main/Student_DNADetectives_Section3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6gYg0nhkY"
      },
      "source": [
        "<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://www.pennmedicine.org/news/-/media/images/pr%20news/news/2021/october/dna.ashx)"
      ],
      "metadata": {
        "id": "Pr77QWsCeJFh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0doqIOEhJBC"
      },
      "source": [
        "# **Goals**\n",
        "In this notebook, you will:\n",
        "*   Learn how to clean up and preprocess genome data\n",
        "*   Convert genomic data into a feature matrix\n",
        "*   Build a logistic regression model predicting the country a SARS-CoV-2 lineage came from based on its genome\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VJHN3yph4Uy"
      },
      "source": [
        "#@title Run this cell to set up the environment { display-mode: \"form\" }\n",
        "!pip install Biopython\n",
        "from Bio import SeqIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from collections import Counter\n",
        "from sklearn import model_selection, linear_model\n",
        "\n",
        "# data_path = 'https://drive.google.com/uc?id=1f1CtRwSohB7uaAypn8iA4oqdXlD_xXL1'\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20DNA%20Detectives/SARS_CoV_2_sequences_global.fasta'\n",
        "cov2_sequences = 'SARS_CoV_2_sequences_global.fasta'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GVs1Qd_iMF3"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPVl67ETxHK5"
      },
      "source": [
        "## **Examining Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4jSF-_jw3oz"
      },
      "source": [
        "We are going to read in a set of SARS-CoV-2 genomes from around the world. Note that sequence #0 is the \"reference sequence\"-- one of the original sequences from Wuhan. These global sequences come from the [NCBI database](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&VirusLineage_ss=SARS-CoV-2,%20taxid:2697049&SLen_i=29000%20TO%2031000&Completeness_s=complete&HostLineage_ss=Homo%20sapiens%20(human),%20taxid:9606).  You can examine the different sequences using the form below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dvPJa6Gegnjw"
      },
      "source": [
        "sequences = [r for r in SeqIO.parse(cov2_sequences, 'fasta')]\n",
        "sequence_num =  1530#@param {type:\"integer\"}\n",
        "print(sequences[sequence_num])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQdJz8Yyz5t"
      },
      "source": [
        "###**Exercise: How many sequences are there?**\n",
        "\n",
        "Note: Sequences have been uploaded/stored in a variable called ```sequences```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L6mli7Gyz5u"
      },
      "source": [
        "n_sequences = None ### YOUR CODE HERE\n",
        "print(f\"There are {n_sequences} sequences\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6cnVm9ExOGu"
      },
      "source": [
        "###**Exercise: How different are the 1st (non-reference) and 10th SARS-CoV-2 sequences?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkwJlRubxicM"
      },
      "source": [
        "sequence_1 = np.array(sequences[0])\n",
        "sequence_10 = np.array(sequences[9])\n",
        "percent_similarity = 0 ### YOUR CODE HERE (Percent similarity between the sequences.)\n",
        "print(\"Sequence 1 and 10 similarity: %\", percent_similarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHqVhusUxJj6"
      },
      "source": [
        "### **Exercise (BONUS):  Make a histogram of the number of mutations each SARS-CoV-2 sequence has compared to the reference genome.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPF5jWPexNmY"
      },
      "source": [
        "reference = np.array(sequences[0])\n",
        "mutations_per_seq = None ### YOUR CODE HERE\n",
        "\n",
        "plt.hist(mutations_per_seq)\n",
        "plt.xlabel('# mutations')\n",
        "plt.ylabel('# sequences')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqgCNKdJ2O4l"
      },
      "source": [
        "Interestingly, it looks like there are a couple sequences with a LOT of mutations! We can investigate these sequences a little more.\n",
        "\n",
        "**Examine some of these sequences with high number of mutations by selecting the minimum # of mutations from the form below. What do you notice about the sequences? Discuss with your instructor and peers.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9VSB3eTzJT0",
        "cellView": "form"
      },
      "source": [
        "min_number_of_mutations  =  340#@param {type:\"integer\"}\n",
        "idx = np.random.choice(np.where(mutations_per_seq>min_number_of_mutations)[0])\n",
        "print(f\"Sequence {idx} has > {min_number_of_mutations} mutations! \\n\")\n",
        "print(sequences[idx], '\\n')\n",
        "print(\"The sequence is composed of: \")\n",
        "Counter(np.array(sequences[idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3_3xSpe20IT"
      },
      "source": [
        "## Missing Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgzI9GyD2h9b"
      },
      "source": [
        "It is hard to see, but some of the sequences have `N` in them. Run the cell below for an example\n",
        "\n",
        "### **Exercise: Calculate the number of sequences that have an ```N``` in them.**\n",
        "\n",
        "**What do you think ```N``` means?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V6-k5GKgYbE"
      },
      "source": [
        "n_sequences_with_N = 0\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "print(f'{n_sequences_with_N} sequences have at least 1 \"N\"!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eno1YJJo2flS"
      },
      "source": [
        "\n",
        "`N` is not a nucleic acid- it just stands for \"missing\", or \"low quality\". \"Missing\" is different than ```_``` or a deletion. At the locations with ```N```, the sequencing machine had low quality data here, so it was unable to determine what base was at that location. We should remember this when we extract our features. Stay tuned for more on sequencing machines and how sequences are built in the bonus notebook of this project!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y4r8Qk64P1n"
      },
      "source": [
        "# **Feature Extraction**\n",
        "\n",
        "We are going to build a model that predicts the country a SARS-CoV-2 virus came from based on its genome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD96VzFr65jR"
      },
      "source": [
        "### **Exercise: Recall the structure of machine learning models.**\n",
        "**In general what two categories of data do we need to build a supervised machine learning model? What will we use for each category?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gVJga_xZ_MP4"
      },
      "source": [
        "_1_  =  'Features' #@param {type:\"string\"}\n",
        "_2_  =  'Labels' #@param {type:\"string\"}\n",
        "\n",
        "print('1. We need a set of FEATURES (X).\\n',\n",
        "      '  Our features will be the genomes of the different sequences.')\n",
        "print('2. We need LABElS (Y).\\n',\n",
        "      '  Our labels will be the country that each sequence came from.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrHyaErMp9fB"
      },
      "source": [
        "**Question: How will we turn our features into a numeric matrix?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A72g_7uSyVP"
      },
      "source": [
        "## Extract Features (X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3ZU8b4fdXo6"
      },
      "source": [
        "Remember that our input must be a *numeric* matrix/table.\n",
        "We are going to create a matrix where our features are the presence/absence of a specific mutation (given by ```<location>```_```<base>```).\n",
        "\n",
        "Our columns will be 1_A, 1_T, 3_G, 4_A, etc.\n",
        "\n",
        "\n",
        "| Sequence ID | 1_A | 1_C | 3_G | 4_A  | ...|\n",
        "|-------------|-----|-----|-----|------|----|\n",
        "|Sequence 1   |  1  |  0  |   1 |    0 |  0 |\n",
        "|Sequence 2   |  0  |  0  |   1 |    0 |  0 |\n",
        "|Sequence 3   |  1  |  0  |   0 |    0 |  0 |\n",
        "|Sequence 4   |  0  |  1  |   0 |    1 |  1 |\n",
        "|Sequence 5   |  1  |  0  |   0 |    0 |  1 |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTy_D41nBYe-"
      },
      "source": [
        "# Note: This can take a couple minutes to run!\n",
        "# but we can monitor our progress using the tqdm library (which creates a progress bar)\n",
        "n_bases_in_seq = len(sequences[0])\n",
        "columns = {}\n",
        "\n",
        "# Iterate though all positions in this sequence.\n",
        "for location in tqdm.tqdm(range(n_bases_in_seq)): # tqdm is a nice library that prints our progress.\n",
        "  bases_at_location = np.array([s[location] for s in sequences])\n",
        "  # If there are no mutations at this position, move on.\n",
        "  if len(set(bases_at_location))==1: continue\n",
        "  for base in ['A', 'T', 'G', 'C', '-']:\n",
        "    feature_values = (bases_at_location==base)\n",
        "\n",
        "    # Set the values of any base that equals 'N' to np.nan.\n",
        "    feature_values[bases_at_location==['N']] = np.nan\n",
        "\n",
        "    # Convert from T/F to 0/1.\n",
        "    feature_values  = feature_values*1\n",
        "\n",
        "    # Make the column name look like <location>_<base> (1_A, 2_G, 3_A, etc.)\n",
        "    column_name = str(location) + '_' + base\n",
        "\n",
        "    # Add column to dict\n",
        "    columns[column_name] = feature_values\n",
        "\n",
        "\n",
        "mutation_df = pd.DataFrame(columns)\n",
        "\n",
        "# Print the size of the feature matrix/table.\n",
        "n_rows = np.shape(mutation_df)[0]\n",
        "n_columns = np.shape(mutation_df)[1]\n",
        "print(f\"Size of matrix: {n_rows} rows x {n_columns} columns\")\n",
        "\n",
        "# Check what the matrix looks like:\n",
        "mutation_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrC_ymFoSs_g"
      },
      "source": [
        "## Extract Label (Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfQVTqPhIYUr"
      },
      "source": [
        "We are going to use the region of the world that each sample came from as the **label**. ![alt text](https://upload.wikimedia.org/wikipedia/commons/3/3d/Flag-map_of_the_world_%282017%29.png)\n",
        "\n",
        "First, let's see how many samples we have from different countries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "pxL3w1MHFx0k"
      },
      "source": [
        "#@title ###**Exercise: Explore the different number of samples that come from each country.**\n",
        "country = \"Pakistan\" #@param dict_keys(['China', 'Kazakhstan', 'India', 'Sri Lanka', 'Taiwan', 'Hong Kong', 'Viet Nam', 'Thailand', 'Nepal', 'Israel', 'South Korea', 'Iran', 'Pakistan', 'Turkey', 'Australia', 'USA']\n",
        "countries = [(s.description).split('|')[-1] for s in sequences]\n",
        "print(f\"There are {Counter(countries)[country]} sequences from {country}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uu2QZpFdzGG"
      },
      "source": [
        "Since some countries only have a couple samples, we are going to use the **region** of the world as our labels.\n",
        "\n",
        "Since we have a large number of samples from Asia, North America, and Oceania, we will filter ours sequences to just these regions. We will convert our countries to regions using the code below.\n",
        "\n",
        "### **Exercise: Convert each country to its region of the world.**\n",
        "**Use the code below to create a dictionary of ```<country>```:```<region>``` where ```region``` is either ```'Oceania'```, ```'North America'```, or ```'Asia'```, and convert each country to region.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "ODOhep8g8LCB"
      },
      "source": [
        "### YOUR CODE HERE: Replace the Nones below!\n",
        "countries_to_regions_dict = {\n",
        "         'Australia': 'Oceania',\n",
        "         'China': 'Asia',\n",
        "         'Hong Kong': None,\n",
        "         'India': None,\n",
        "         'Nepal': None,\n",
        "         'South Korea': None,\n",
        "         'Sri Lanka': None,\n",
        "         'Taiwan': None,\n",
        "         'Thailand': None,\n",
        "         'USA': None,\n",
        "         'Viet Nam': None\n",
        "}\n",
        "\n",
        "regions = [countries_to_regions_dict[c] if c in\n",
        "           countries_to_regions_dict else 'NA' for c in countries]\n",
        "mutation_df['label'] = regions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXuNJGj0K94L"
      },
      "source": [
        "**Now see how many samples there are from each region of the world.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "R8xUF_S-K809"
      },
      "source": [
        "region = \"Asia\" #@param ['Oceania', 'North America', 'Asia']\n",
        "print(f\"There are {Counter(regions)[region]} sequences from {region}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxVN5LnFLX4X"
      },
      "source": [
        "## Balancing the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCfkZVGnkCLL"
      },
      "source": [
        "Recall that ML models work the best if we have *balanced* data- a dataset with equal numbers of samples with each label. Run the following code to remove duplicate samples from the dataset, and then balance the samples.\n",
        "\n",
        "### **Exercise: Balance the data equally between samples from Asia, Oceania, and North America**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsGQiLUzL0hI"
      },
      "source": [
        "balanced_df = mutation_df.copy()\n",
        "balanced_df['label'] = regions\n",
        "balanced_df = balanced_df[balanced_df.label!='NA']\n",
        "balanced_df = balanced_df.drop_duplicates()\n",
        "samples_north_america = balanced_df[balanced_df.label == None] ### YOUR CODE HERE\n",
        "samples_oceania = balanced_df[balanced_df.label == None] ### YOUR CODE HERE\n",
        "samples_asia = balanced_df[balanced_df.label == None] ### YOUR CODE HERE\n",
        "\n",
        "# Number of samples we will use from each region.\n",
        "n = min(len(samples_north_america), None, None) ### YOUR CODE HERE\n",
        "\n",
        "balanced_df = pd.concat([samples_north_america[:n],\n",
        "                    samples_asia[:n],\n",
        "                    samples_oceania[:n]])\n",
        "print(\"Number of samples in each region: \", Counter(balanced_df['label']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJBRsrulXnUG"
      },
      "source": [
        "# **Logistic Regression Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwZJYgOxQx11"
      },
      "source": [
        "***Congrats!***  We finally are done with preprocessing/cleaning our data! Although tedious, this is an important part of doing machine learning in biology. The data can be complex and messy, and if we don't do some cleaning up beforehand, our models will have poor performance.\n",
        "\n",
        "\n",
        "![](https://media.makeameme.org/created/we-did-it-3b3ac27d2a.jpg)\n",
        "\n",
        "\n",
        "Finally, run the code to set up a ```X``` feature matrix and a ```Y``` label list from our ```balanced_df```. You can explore the different values using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "p5Ebb7WuO1Oq"
      },
      "source": [
        "X = balanced_df.drop('label', axis=1)\n",
        "Y = balanced_df.label\n",
        "data = \"X (features)\" #@param ['X (features)', 'Y (label)']\n",
        "start = 1 #@param {type:'integer'}\n",
        "stop =  10#@param {type:'integer'}\n",
        "\n",
        "if start>=stop:print(\"Start must be < stop!\")\n",
        "else:\n",
        "  if data=='X (features)':\n",
        "    print(X.iloc[start:stop])\n",
        "  if data=='Y (label)':\n",
        "    print(Y[start:stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q-biY64sS94"
      },
      "source": [
        "In preparation for training and testing our model, we need to import two key functions:\n",
        "\n",
        "* `train_test_split()`, used to split the data into training and testing portions, and\n",
        "* `accuracy_score()`, for testing the accuracy of our model's predictions against the labels in our testing data.\n",
        "\n",
        "Run the next code block to import these functions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJHosdLWsU2t"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4fAOFq3iqFl"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcksFwDLlOsE"
      },
      "source": [
        "We will be using the logistic regression model we have learned about with one modification. We will use the \"multinomial\" class of logistic regression model.  This is used when there are more than 2 categories in the label set. In our case, we have ```Asia```, ```North America```, and ```Oceania``` as our possible labels.\n",
        "\n",
        "### **Exercise: Train the model using the standard pipeline you have mastered!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbxYkappX6Y6"
      },
      "source": [
        "lm = linear_model.LogisticRegression(\n",
        "    multi_class=\"multinomial\", max_iter=1000,\n",
        "    fit_intercept=False, tol=0.001, solver='saga', random_state=42)\n",
        "\n",
        "# Split into training/testing set. Use a testing size of 0.2\n",
        "X_train, X_test, y_train, y_test = ### YOUR CODE HERE\n",
        "\n",
        "# Train/fit model\n",
        "### YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEoMF1rGisxC"
      },
      "source": [
        "## **Testing/Evaluation**\n",
        "\n",
        "In addition to printing the accuracy of a model, we can also use a *confusion matrix* to see how well the model performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXLmY1hfqGT7"
      },
      "source": [
        "###**Exercise: Evaluate the model on the test set.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "JYGTYPopp5WR"
      },
      "source": [
        "# Predict on the test set.\n",
        "y_pred = None ### YOUR CODE HERE\n",
        "\n",
        "# Compute accuracy.\n",
        "accuracy = None ### YOUR CODE HERE\n",
        "print(\"Accuracy: %\", accuracy)\n",
        "\n",
        "# Compute confusion matrix.\n",
        "confusion_mat = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
        "confusion_mat.columns = [c + ' predicted' for c in lm.classes_]\n",
        "confusion_mat.index = [c + ' true' for c in lm.classes_]\n",
        "\n",
        "print(confusion_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HwrfLGMKaG4"
      },
      "source": [
        "# **Wrapping Up!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAgFs2spqoHF"
      },
      "source": [
        "***Great job!*** You built a pretty accurate model that uses genomic data to predict what country a SARS-CoV-2 sample comes from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dsiiqHD5qzOg"
      },
      "source": [
        "#@title #### **Exercise: To wrap up, write a couple of sentences explaining how your model performed.**\n",
        "Response = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}